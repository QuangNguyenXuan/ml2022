{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyM7IzS8FKYNpDZwycxjqa/s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#SENTIMENT ANALYSIS\n","**AI VIET NAM**\n","**thai.nq07@gmail.com**"],"metadata":{"id":"2-XqZZCjlNIZ"}},{"cell_type":"markdown","source":["Hoàn thành code trong phần **### START CODE HERE ... ### END CODE HERE** dựa vào gợi ý và kết quả mong đợi!"],"metadata":{"id":"umqXUZVUIBMD"}},{"cell_type":"markdown","source":["##1.Naive Bayes Classifier"],"metadata":{"id":"jOCF9tKlIspw"}},{"cell_type":"code","source":["# Tập dữ liệu ví dụ\n","\n","train_x = [\n","           'just plain boring',\n","           'entirely predictable and lacks energy',\n","           'no surprises and very few laughs',\n","           'very powerful',\n","           'the most fun film of the summer'\n","]\n","train_y = [0, 0, 0, 1, 1]"],"metadata":{"id":"PmuEZmB47rmN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###1.1. Tiền xử lý dữ liệu cơ bản"],"metadata":{"id":"HZp30Q5ZJBSr"}},{"cell_type":"code","source":["def basic_preprocess(text):\n","    \"\"\" Tiền xử lý và tách các câu\n","    Args:\n","        text: câu đầu vào. \n","        VD: \"Tôi đi học\"\n","    Output:\n","        text_clean: danh sách các từ (token) sau khi chuyển sang chữ thường và\n","            được phân tách bởi khoảng trắng\n","    \"\"\"\n","    text_clean = text.lower()\n","    return text_clean.split()\n","\n","basic_preprocess(train_x[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G4_6pcOfI_TN","executionInfo":{"status":"ok","timestamp":1665744705919,"user_tz":-420,"elapsed":11,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"c9645ad0-e757-49b0-9ed1-278014f0606b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['just', 'plain', 'boring']"]},"metadata":{},"execution_count":102}]},{"cell_type":"markdown","source":["###1.2.Xây dựng bộ từ điển"],"metadata":{"id":"JoUOaYc3KFg4"}},{"cell_type":"code","source":["#Ex 1\n","def count_freq_words(corpus, labels):\n","    \"\"\" Xây dựng bộ từ điển tần suất xuất hiện của các từ\n","    Args:\n","        corpus: tập danh sách các câu\n","        labels: tập nhãn tương ứng với các câu trong corpus (0 hoặc 1)\n","    Output:\n","        model: bộ từ điển ánh xạ mỗi từ và tần suất xuất hiện của từ đó trong corpus\n","            key: (word, label)\n","            value: frequency\n","            VD: {('boring', 0): 2} => từ boring xuất hiện 2 lần trong các sample thuộc class 0\n","    \"\"\"\n","    model = {}\n","    for label, sentence in zip(labels, corpus):\n","        for word in basic_preprocess(sentence):\n","            ### START CODE HERE\n","\n","            # Định nghĩa key của model là tuple (word, label)\n","            # Nếu key đã tồn tại trong model thì tăng value lên 1\n","            # Nếu key chưa tồn tại trong model thì bổ sung key vào model với value =1\n","\n","            ### END CODE HERE\n","            pass\n","    return model"],"metadata":{"id":"pLBbhdq_LScc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Kết quả mong đợi\n","freqs = count_freq_words(train_x, train_y)\n","freqs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wdDMOM-9MURU","executionInfo":{"status":"ok","timestamp":1665750217589,"user_tz":-420,"elapsed":392,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"b97856c3-2ee9-4737-e9b0-ae2718fb80e4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{('just', 0): 1,\n"," ('plain', 0): 1,\n"," ('boring', 0): 1,\n"," ('entirely', 0): 1,\n"," ('predictable', 0): 1,\n"," ('and', 0): 2,\n"," ('lacks', 0): 1,\n"," ('energy', 0): 1,\n"," ('no', 0): 1,\n"," ('surprises', 0): 1,\n"," ('very', 0): 1,\n"," ('few', 0): 1,\n"," ('laughs', 0): 1,\n"," ('very', 1): 1,\n"," ('powerful', 1): 1,\n"," ('the', 1): 2,\n"," ('most', 1): 1,\n"," ('fun', 1): 1,\n"," ('film', 1): 1,\n"," ('of', 1): 1,\n"," ('summer', 1): 1}"]},"metadata":{},"execution_count":121}]},{"cell_type":"code","source":["# Hàm lấy ra tần suất xuất hiện là value trong `freq` dựa vào key (word, label)\n","def lookup(freqs, word, label):\n","    '''\n","    Args:\n","        freqs: a dictionary with the frequency of each pair\n","        word: the word to look up\n","        label: the label corresponding to the word\n","    Output:\n","        count: the number of times the word with its corresponding label appears.\n","    '''\n","    count = 0\n","\n","    pair = (word, label)\n","    if pair in freqs:\n","        count = freqs[pair]\n","\n","    return count\n","\n","lookup(freqs, \"just\", 0)"],"metadata":{"id":"9Gw126f5pTqJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665750238247,"user_tz":-420,"elapsed":397,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"c0bf84fb-4f42-4785-dcdf-106995469361"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":122}]},{"cell_type":"markdown","source":["###1.3.Thuật toán phân loại Naive Bayes\n","**Bước 1: Tính xác suất tiên nghiệm của các class**\n","- Tính $D$, $D_{pos}$, $D_{neg}$\n","    - Dựa vào `train_y` tính số lượng các sample có trong tập training: $D$, số lượng các sample là positive (nhãn 1): $D_{pos}$ và số lượng nhãn là negative (nhãn 0): $D_{neg}$\n","    - Tính xác suất tiên nghiệm của class 1 là: $P(D_{pos})=D_{pos}/D$, và class 0 là: $P(D_{pos})=D_{pos}/D$"],"metadata":{"id":"AaSqdNkUNdiI"}},{"cell_type":"code","source":["# Ex 2\n","def compute_prior_prob(train_y):\n","    # Tính D, D_pos, D_neg dựa vào x_train\n","    ### START CODE HERE\n","    # Tính D, số lượng các sample trong training\n","    D\n","    # Tính D_pos, số lượng các positive sample trong training\n","    D_pos\n","    # Tính D_neg, số lượng các negative sample trong training\n","    D_neg\n","    ### END CODE HERE\n","    # Tính xác suất tiên nghiệm cho các class 0 và 1\n","    p_prior = {0:(D_neg/D), 1:(D_pos/D)}\n","    return p_prior"],"metadata":{"id":"tAaPBeBCgDSZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Kết quả mong đợi\n","compute_prior_prob(train_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ms7OTsAEf30f","executionInfo":{"status":"ok","timestamp":1665750262773,"user_tz":-420,"elapsed":685,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"d70a53e7-3b83-435f-d679-7c3d326b98d5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 0.6, 1: 0.4}"]},"metadata":{},"execution_count":124}]},{"cell_type":"markdown","source":["**Bước 2: Tính xác suất likelihood**\n","- Tính $V$: Dựa vào `freqs` tính số lượng các từ duy nhất (uniqe words) - gọi là bộ từ điển\n","\n","- Tính $N_{pos}$ và $N_{neg}$: Dựa vào `freqs` dictionary, tính tổng số từ (có thể trùng lặp) xuất hiện trong positive samples $N_{pos}$ và negative samples $N_{neg}$.\n","\n","- Tính tần suất xuất hiện của mỗi từ trong positive samples $freq_{pos}$ và trong negative samples $freq_{neg}$\n","\n","- Tính xác suất likelihood mỗi từ trong bộ từ điển\n","    - Sử dụng hàm `lookup` lấy ra tần suất xuất hiện của từ là positive $freq_{pos}$, và tần xuất xuất hiện của từ là negative $freq_{neg}$\n","- Tính xác suất cho mỗi từ thuộc vào positive sample: $P(W_{pos})$, thuộc vào negative sample $P(W_{neg})$ sử dụng công thức 4 & 5.\n","\n","$$ P(W_{pos}) = \\frac{freq_{pos} + 1}{N_{pos} + V}\\tag{4} $$\n","$$ P(W_{neg}) = \\frac{freq_{neg} + 1}{N_{neg} + V}\\tag{5} $$\n","\n","**Note:** Chúng ta lưu trữ likelihood của mỗi từ vào dictionary với key (từ): $W$, value (dictionary): ${0: P(W_{pos}), 1: P(W_{pos})}$"],"metadata":{"id":"9cnux4rwgsNK"}},{"cell_type":"code","source":["# Ex 3\n","def compute_likelihood(freqs):\n","    # Tính xác suất likelihood của mỗi từ trong bộ từ điển\n","\n","    ### START CODE HERE\n","    # Tính V các từ duy nhất xuất hiện trong tập train\n","    vocab\n","    V = len(vocab)\n","\n","    # Tính N_pos: số lượng từ trong positive samples và N_neg: số từ trong negative sample\n","    N_pos = N_neg = 0\n","    print(f'V: {V}, N_pos: {N_pos}, N_neg: {N_neg}')\n","\n","    # Tính likelihood cho mỗi từ trong bộ từ điển\n","    p_likelihood = {}\n","    for word in vocab:\n","        # Lấy tần xuất xuất hiện của mỗi từ là positive hoặc negative\n","        freq_pos\n","        freq_neg\n","\n","        # Tính xác suất likelihood của mỗi từ với class positive và negative\n","        p_w_pos \n","        p_w_neg\n","\n","        # Lưu vào p_likelihood dictionary\n","        p_likelihood[word] = {0:p_w_neg, 1:p_w_pos}\n","    # END CODE HERE\n","    \n","    return p_likelihood"],"metadata":{"id":"_aqBveSjoqCX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Kết quả mong đợi\n","compute_likelihood(freqs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Qc94FJqog-G","executionInfo":{"status":"ok","timestamp":1665750277516,"user_tz":-420,"elapsed":8,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"1c550830-ddcd-4d97-8702-834be5829387"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["V: 20, N_pos: 9, N_neg: 14\n"]},{"output_type":"execute_result","data":{"text/plain":["{'very': {0: 0.058823529411764705, 1: 0.06896551724137931},\n"," 'fun': {0: 0.029411764705882353, 1: 0.06896551724137931},\n"," 'most': {0: 0.029411764705882353, 1: 0.06896551724137931},\n"," 'film': {0: 0.029411764705882353, 1: 0.06896551724137931},\n"," 'boring': {0: 0.058823529411764705, 1: 0.034482758620689655},\n"," 'summer': {0: 0.029411764705882353, 1: 0.06896551724137931},\n"," 'predictable': {0: 0.058823529411764705, 1: 0.034482758620689655},\n"," 'plain': {0: 0.058823529411764705, 1: 0.034482758620689655},\n"," 'powerful': {0: 0.029411764705882353, 1: 0.06896551724137931},\n"," 'of': {0: 0.029411764705882353, 1: 0.06896551724137931},\n"," 'the': {0: 0.029411764705882353, 1: 0.10344827586206896},\n"," 'entirely': {0: 0.058823529411764705, 1: 0.034482758620689655},\n"," 'no': {0: 0.058823529411764705, 1: 0.034482758620689655},\n"," 'few': {0: 0.058823529411764705, 1: 0.034482758620689655},\n"," 'laughs': {0: 0.058823529411764705, 1: 0.034482758620689655},\n"," 'just': {0: 0.058823529411764705, 1: 0.034482758620689655},\n"," 'energy': {0: 0.058823529411764705, 1: 0.034482758620689655},\n"," 'lacks': {0: 0.058823529411764705, 1: 0.034482758620689655},\n"," 'surprises': {0: 0.058823529411764705, 1: 0.034482758620689655},\n"," 'and': {0: 0.08823529411764706, 1: 0.034482758620689655}}"]},"metadata":{},"execution_count":126}]},{"cell_type":"markdown","source":["**Bước 3: Hoàn thiện `train` function cho Naive Bayes***"],"metadata":{"id":"fzzrMkeQo_wu"}},{"cell_type":"code","source":["def train_naive_bayes(train_x, train_y):\n","    ''' Huấn luyện thuật toán Naive Bayes\n","    Args:\n","        train_x: Danh sách các câu\n","        train_y: Danh sách các nhãn tương ứng (0 hoặc 1)\n","    Output:\n","        p_prior: the prior probability (Xác suấ tiên nghiệm)\n","        p_likelihood: the maximum likelihood of the probability.\n","    '''\n","    # Xây dựng từ điển tần suất xuất hiện của từ và nhãn tương ứng\n","    freqs = count_freq_words(train_x, train_y)\n","\n","    # Tính xác suất tiên nghiệm\n","    p_prior = compute_prior_prob(train_y)\n","\n","    # Tính xác suất likelihood\n","    p_likelihood = compute_likelihood(freqs)\n","\n","    return p_prior, p_likelihood"],"metadata":{"id":"Q2patcrx8Gfh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Kết quả đầu ra thu được khi huấn luận Naive Bayes Classifier\n","p_prior, p_likelihood = train_naive_bayes(train_x, train_y)\n","p_prior, p_likelihood"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7739wp07pqa6","executionInfo":{"status":"ok","timestamp":1665750307564,"user_tz":-420,"elapsed":8,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"ac0a14c5-4440-41f3-9ad7-5f2d62ced208"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["V: 20, N_pos: 9, N_neg: 14\n"]},{"output_type":"execute_result","data":{"text/plain":["({0: 0.6, 1: 0.4},\n"," {'very': {0: 0.058823529411764705, 1: 0.06896551724137931},\n","  'fun': {0: 0.029411764705882353, 1: 0.06896551724137931},\n","  'most': {0: 0.029411764705882353, 1: 0.06896551724137931},\n","  'film': {0: 0.029411764705882353, 1: 0.06896551724137931},\n","  'boring': {0: 0.058823529411764705, 1: 0.034482758620689655},\n","  'summer': {0: 0.029411764705882353, 1: 0.06896551724137931},\n","  'predictable': {0: 0.058823529411764705, 1: 0.034482758620689655},\n","  'plain': {0: 0.058823529411764705, 1: 0.034482758620689655},\n","  'powerful': {0: 0.029411764705882353, 1: 0.06896551724137931},\n","  'of': {0: 0.029411764705882353, 1: 0.06896551724137931},\n","  'the': {0: 0.029411764705882353, 1: 0.10344827586206896},\n","  'entirely': {0: 0.058823529411764705, 1: 0.034482758620689655},\n","  'no': {0: 0.058823529411764705, 1: 0.034482758620689655},\n","  'few': {0: 0.058823529411764705, 1: 0.034482758620689655},\n","  'laughs': {0: 0.058823529411764705, 1: 0.034482758620689655},\n","  'just': {0: 0.058823529411764705, 1: 0.034482758620689655},\n","  'energy': {0: 0.058823529411764705, 1: 0.034482758620689655},\n","  'lacks': {0: 0.058823529411764705, 1: 0.034482758620689655},\n","  'surprises': {0: 0.058823529411764705, 1: 0.034482758620689655},\n","  'and': {0: 0.08823529411764706, 1: 0.034482758620689655}})"]},"metadata":{},"execution_count":128}]},{"cell_type":"markdown","source":["###1.4.Dự đoán với các mẫu thử nghiệm\n","- Tính xác suất của mỗi sample (n từ) dựa vào công thức:\n","$$P(0).P(S|0) = P(0).P(w_{1}|0).P(w_{2}|0)...P(w_{n}|0)$$ "],"metadata":{"id":"EUmfzZwip2x3"}},{"cell_type":"code","source":["# Ex 4\n","def naive_bayes_predict(sentence, p_prior, p_likelihood):\n","    '''\n","    Args:\n","        sentence: a string\n","        p_prior: a dictionary of the prior probability\n","        p_likelihood: a dictionary of words mapping to the probability\n","    Output:\n","        p: the probability of sentence with 0: negative, 1: positive\n","\n","    '''\n","    # Tiền xử lý dữ liệu\n","    words = basic_preprocess(sentence)\n","\n","    # Khởi tạo giá trị xác suất ban đầu là giá trị xác suất tiên nghiệm\n","    p_neg = p_prior[0]\n","    p_pos = p_prior[1]\n","\n","    for word in words:\n","        # Kiểm tra xem word có tồn tại trong p_likelihood hay không\n","        if word in p_likelihood:\n","            ### START CODE HERE\n","            # nhân xác suất tiên nghiệm với xác suất likelihood của các từ\n","            ### END CODE HERE\n","    return {'prob': {0: p_neg, 1: p_pos},\n","            'label': 0 if p_neg > p_pos else 1}"],"metadata":{"id":"ob-nYjpIr7Pb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Kết quả mong đợi\n","sentence = \"predictable with no fun\"\n","naive_bayes_predict(sentence, p_prior, p_likelihood)"],"metadata":{"id":"gd3X74kBAnrK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##2.Naive Bayes Classfier for Sentiment Analysis on Tweets\n","**Phân tích cảm xúc trên tập 1Tweets1 sử dụng thuật toán phân loại Naive Bayes**"],"metadata":{"id":"HGFYVt0IBL_0"}},{"cell_type":"code","source":["import re\n","import string\n","import nltk\n","import numpy as np\n","nltk.download('twitter_samples')\n","from nltk.corpus import twitter_samples\n","from nltk.tokenize import TweetTokenizer\n","from tqdm import tqdm"],"metadata":{"id":"KVAHBqV7But_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665750329521,"user_tz":-420,"elapsed":652,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"5f82b775-94c0-456b-f0fd-2c50204bbb02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n","[nltk_data]   Package twitter_samples is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["###2.1.Dowload Dataset"],"metadata":{"id":"7aC78vV6Bh_x"}},{"cell_type":"code","source":["# Tải về tập dữ liệu tweets\n","all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n","all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n","\n","# Chia thành 2 tập train và test\n","# train: 4000 samples, test: 1000 samples\n","train_pos = all_positive_tweets[:4000]\n","test_pos = all_positive_tweets[4000:]\n","\n","train_neg = all_negative_tweets[:4000]\n","test_neg = all_negative_tweets[4000:]\n","\n","train_x = train_pos + train_neg\n","test_x = test_pos + test_neg\n","\n","# Tạo nhãn negative: 0, positive: 1\n","train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n","test_y = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))"],"metadata":{"id":"C36MnzNxBhdE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###2.2.Tiền xử lý dữ liệu cho tập `Tweets`"],"metadata":{"id":"uRFnS6IaCf_k"}},{"cell_type":"code","source":["all_positive_tweets[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v2Dz3mYCrZkZ","executionInfo":{"status":"ok","timestamp":1665750333770,"user_tz":-420,"elapsed":9,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"0e7e0cc5-5f24-4c98-dc00-a3622e0e3d3c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)',\n"," '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!',\n"," '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!',\n"," '@97sides CONGRATS :)',\n"," 'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark on my fb profile :) in 15 days',\n"," '@BhaktisBanter @PallaviRuhail This one is irresistible :)\\n#FlipkartFashionFriday http://t.co/EbZ0L2VENM',\n"," \"We don't like to keep our lovely customers waiting for long! We hope you enjoy! Happy Friday! - LWWF :) https://t.co/smyYriipxI\",\n"," '@Impatientraider On second thought, there’s just not enough time for a DD :) But new shorts entering system. Sheep must be buying.',\n"," 'Jgh , but we have to go to Bayan :D bye',\n"," 'As an act of mischievousness, am calling the ETL layer of our in-house warehousing app Katamari.\\n\\nWell… as the name implies :p.']"]},"metadata":{},"execution_count":133}]},{"cell_type":"markdown","source":["Dựa vào việc quan sát tập dữ liệu trên chúng ta tiến hàng một số bước tiền xử lý như sau:\n","- Xóa bỏ các hashtags như #FollowFriday,...\n","- Xóa bỏ các thẻ gắn nhãn các tài khoản như: @Lamb2ja\n","- Xóa bỏ các thẻ HTML, CSS,.. có thể có như: https://t.co/smyYriipxI\n","- Xóa bỏ retweet trong text: \"RT\"\n","- Xóa bỏ dấu câu và có thể xóa hết số, ký tự đặc biệt (Với mục đích tập trung ngữ nghĩa các từ)\n","- Có thể thực hiện một số bước tiền xử lý khác\n","- Sau khi tiền xử lý xong chúng ta tiến hành tách câu thành các từ (word base tokenizer). Ở đây chúng ta sẽ dùng bộ tách từ có sẵn cho tách từ `tweet` của nltk là `TweetTokenizer`"],"metadata":{"id":"GFezH6Udrdkx"}},{"cell_type":"code","source":["# Ex 5\n","def basic_preprocess(text):\n","    '''\n","    Args:\n","        text: câu đầu vào\n","    Output:\n","        text_clean: danh sách các từ (token) sau khi chuyển sang chữ thường và\n","            được phân tách bởi khoảng trắng\n","    '''\n","    ### START CODE\n","    # xóa bỏ stock market tickers like $GE\n","    # xóa bỏ old style retweet text \"RT\"\n","    # xóa bỏ hyperlinks\n","    # xóa bỏ hashtags\n","    # tokenize\n","    #xóa dấu câu, số, ký tự đặc biệt\n","    ### END CODE\n","    return text_clean"],"metadata":{"id":"YJ_0y4bEt5RV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Kết quả mong đợi\n","example_sentence = \"RT @Twitter @chapagain Hello There! Have a great day. #good #morning http://chapagain.com.np\"\n","basic_preprocess(example_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GQlY1fXNDZaI","executionInfo":{"status":"ok","timestamp":1665750400023,"user_tz":-420,"elapsed":11,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"ad0722c4-7fd7-4d4d-934c-4ef07e35ef25"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['hello', 'there', 'have', 'a', 'great', 'day', 'good', 'morning']"]},"metadata":{},"execution_count":139}]},{"cell_type":"markdown","source":["###2.3.Huấn luyện Naive Bayes Classifier trên tập `Tweets`"],"metadata":{"id":"DthCUZiZEL3d"}},{"cell_type":"code","source":["p_prior, p_likelihood = train_naive_bayes(train_x, train_y)"],"metadata":{"id":"oFYN8KLqEQiZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665750405814,"user_tz":-420,"elapsed":1353,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"a704645e-ae54-44d1-d7aa-a5536a3ac5d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["V: 10841, N_pos: 41916, N_neg: 43321\n"]}]},{"cell_type":"code","source":["#Kết quả ví dụ về xác suất tiên nghiệm và likelihood của từ happy\n","p_prior, p_likelihood['happy']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZ1yd1jHEXtm","executionInfo":{"status":"ok","timestamp":1665750406621,"user_tz":-420,"elapsed":6,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"efa87e79-43a9-40da-e9ee-8ef6127b659b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({0: 0.5, 1: 0.5}, {0: 0.0003507994534913777, 1: 0.0028432245957882366})"]},"metadata":{},"execution_count":141}]},{"cell_type":"markdown","source":["###2.4.Dự đoán"],"metadata":{"id":"4idaGXBhEz6F"}},{"cell_type":"code","source":["test_x[0], test_y[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4vEDeak7E5Kv","executionInfo":{"status":"ok","timestamp":1665750410175,"user_tz":-420,"elapsed":5,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"dfbebb0b-5457-41c8-cb8d-c04a65298025"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('Bro:U wan cut hair anot,ur hair long Liao bo\\nMe:since ord liao,take it easy lor treat as save $ leave it longer :)\\nBro:LOL Sibei xialan',\n"," 1.0)"]},"metadata":{},"execution_count":142}]},{"cell_type":"code","source":["naive_bayes_predict(test_x[0], p_prior, p_likelihood)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EBBit3jiE3iU","executionInfo":{"status":"ok","timestamp":1665750412325,"user_tz":-420,"elapsed":6,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"d2c9e759-681b-4e4b-9f4c-f78293a7642c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'prob': {0: 1.1032955242760357e-80, 1: 2.0993946427583525e-79}, 'label': 1}"]},"metadata":{},"execution_count":143}]},{"cell_type":"markdown","source":["###2.5.Đánh giá độ chính xác trên tập test"],"metadata":{"id":"tt6FeZSsFxOV"}},{"cell_type":"code","source":["acc = 0\n","for sentence, label in zip(test_x, test_y):\n","\n","    # predic each sentence in test set\n","    pred = naive_bayes_predict(sentence, p_prior, p_likelihood)['label']\n","\n","    # compare predict label with target label\n","    if int(pred) == int(label):\n","        acc += 1\n","\n","print('Accuracy: ', acc/len(test_x))"],"metadata":{"id":"wmihnaRYFwpD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##3.Logistic Regression for Sentiment Analysis on Tweets"],"metadata":{"id":"nQGEMKVNwlO3"}},{"cell_type":"markdown","source":["###3.1.Download Dataset\n","Tương tự như mục 2.1"],"metadata":{"id":"h3QCFT7XxI6P"}},{"cell_type":"code","source":["# Tải về tập dữ liệu tweets\n","all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n","all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n","\n","# Chia thành 2 tập train và test\n","# train: 4000 samples, test: 1000 samples\n","train_pos = all_positive_tweets[:4000]\n","test_pos = all_positive_tweets[4000:]\n","\n","train_neg = all_negative_tweets[:4000]\n","test_neg = all_negative_tweets[4000:]\n","\n","train_x = train_pos + train_neg\n","test_x = test_pos + test_neg\n","\n","# Tạo nhãn negative: 0, positive: 1\n","train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n","test_y = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))"],"metadata":{"id":"Yf4Qx4c9xIbz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###3.2. Tiền xử lý dữ liệu cho tập Tweets"],"metadata":{"id":"FFf5CnXsxcMc"}},{"cell_type":"code","source":["# Ex 6\n","def basic_preprocess(text):\n","    '''\n","    Args:\n","        text: câu đầu vào\n","    Output:\n","        text_clean: danh sách các từ (token) sau khi chuyển sang chữ thường và\n","            được phân tách bởi khoảng trắng\n","    '''\n","    ### START CODE\n","    \n","    ### END CODE\n","    return text_clean"],"metadata":{"id":"wIvAJWRsxj00"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Kết quả đầu ra\n","example_sentence = \"RT @Twitter @chapagain Hello There! Have a great day. #good #morning http://chapagain.com.np\"\n","basic_preprocess(example_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_XATJOCVxmgi","executionInfo":{"status":"ok","timestamp":1665750434798,"user_tz":-420,"elapsed":397,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"063daac1-6d26-4597-efac-544c112a7631"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['hello', 'there', 'have', 'a', 'great', 'day', 'good', 'morning']"]},"metadata":{},"execution_count":147}]},{"cell_type":"markdown","source":["###3.3.Logistic Regression"],"metadata":{"id":"fNj5wW7sxq4O"}},{"cell_type":"markdown","source":["####Sigmoid\n","The sigmoid function: \n","\n","$$ h(z) = \\frac{1}{1+\\exp^{-z}} \\tag{1}$$\n"],"metadata":{"id":"4h6A0zx_xvEk"}},{"cell_type":"code","source":["# Ex 7\n","def sigmoid(z): \n","    '''\n","    Args:\n","        z: is the input (can be a scalar or an array)\n","    Output:\n","        h: the sigmoid of z\n","    '''\n","    \n","    ### START CODE HERE\n","    # calculate the sigmoid of z\n","    \n","    ### END CODE HERE ###\n","    \n","    return h"],"metadata":{"id":"jvvgQPvryxUk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Kết quả kiểm tra hàm sigmpoid\n","sigmoid(0) == 0.5, sigmoid(4.92) == 0.9927537604041685"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TlgxGHCmykTs","executionInfo":{"status":"ok","timestamp":1665750453269,"user_tz":-420,"elapsed":10,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"894af0d9-852c-44a9-d0ed-7a02c49555a6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(True, True)"]},"metadata":{},"execution_count":152}]},{"cell_type":"markdown","source":["#### Gradient Descent Function\n","* Số vòng lặp huấn luyện mô hình: `num_iters`\n","* Với mỗi vòng lặp chúng ta sẽ tính `logits-z`, cost và cập nhật trọng số\n","* Số samples training: `m`, số features trên mỗi sample: `n`\n","* Trọng số mô hình:  \n","$$\\mathbf{\\theta} = \\begin{pmatrix}\n","\\theta_0\n","\\\\\n","\\theta_1\n","\\\\ \n","\\theta_2 \n","\\\\ \n","\\vdots\n","\\\\ \n","\\theta_n\n","\\end{pmatrix}$$\n","\n","* Tính `logits-z`:   $$z = \\mathbf{x}\\mathbf{\\theta}$$\n","    * $\\mathbf{x}$ có chiều (m, n+1) \n","    * $\\mathbf{\\theta}$: có chiều (n+1, 1)\n","    * $\\mathbf{z}$: có chiều (m, 1)\n","* Dự đoán y_hat có chiều (m,1):$$\\widehat{y}(z) = sigmoid(z)$$\n","* Cost function $J$:\n","$$J = \\frac{-1}{m} \\times \\left(\\mathbf{y}^T \\cdot log(\\mathbf{h}) + \\mathbf{(1-y)}^T \\cdot log(\\mathbf{1-h}) \\right)$$\n","* Cập nhật `theta`:\n","$$\\mathbf{\\theta} = \\mathbf{\\theta} - \\frac{\\alpha}{m} \\times \\left( \\mathbf{x}^T \\cdot \\left( \\mathbf{h-y} \\right) \\right)$$"],"metadata":{"id":"6k_Z1YoszL70"}},{"cell_type":"code","source":["# Ex 8\n","def gradient_descent(x, y, theta, alpha, num_iters):\n","    '''\n","    Args:\n","        x: matrix of features, có chiều (m,n+1)\n","        y: label tương ứng (m,1)\n","        theta: vector trọng số (n+1,1)\n","        alpha: tốc độ học\n","        num_iters: số vòng lặp\n","    Output:\n","        J: final cost\n","        theta: vector trọng số\n","    '''\n","    ### START CODE HERE\n","    # lấy m số lượng các sample trong matrix x\n","    m = len(x)\n","    \n","    for i in range(0, num_iters):\n","        # Tính z, phép dot product: x và theta\n","        # Tính y_hat: sigmoid của z\n","        # Tính cost function\n","        # Cập nhật trọn số theta\n","\n","    ### END CODE HERE ###\n","    return J, theta"],"metadata":{"id":"fBq9id8h3t9c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Kiểm qua kết quả\n","np.random.seed(1)\n","\n","# X input: 10 x 3, bias là 1\n","tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n","\n","# Y label: 10 x 1\n","tmp_Y = (np.random.rand(10, 1) > 0.5).astype(float)\n","\n","# Apply gradient descent\n","tmp_J, tmp_theta = gradient_descent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 100)\n","print(f\"\\nCost {tmp_J.item()}\")\n","print(f\"Weight {tmp_theta}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BhMFCHJG4K_q","executionInfo":{"status":"ok","timestamp":1665750463318,"user_tz":-420,"elapsed":14,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"90e81f0c-cae9-408f-80ac-d2382ca1c6fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [00:00<00:00, 14440.71it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Cost 0.6860551249930995\n","Weight [[8.95483666e-08]\n"," [7.01794701e-05]\n"," [4.66109371e-05]]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["###3.4.Trích xuất các feature\n","Chuyển từ `tweet` sang feature\n","Với mỗi `tweet` sẽ được biểu diễn bởi 2 feature (Dựa vào `freq` tương tự ở mục #1 và #2):\n","- số lượng các positive words\n","- số lượng các negative words"],"metadata":{"id":"fnnZJKKn5Unz"}},{"cell_type":"code","source":["# Ex 9\n","def extract_features(text, freqs):\n","    '''\n","    Args: \n","        text: tweet\n","        freqs: bộ từ điển tần suất xuất hiện của từ theo label (word, label)\n","    Output: \n","        x: vector feature có chiều (1,3)\n","    '''\n","    # tiền xử lý\n","    word_l = basic_preprocess(text)\n","    \n","    # 3 thành phần: bias, feature 1 và feature 2\n","    x = np.zeros((1, 3)) \n","    \n","    # bias\n","    x[0,0] = 1 \n","    \n","    ### START CODE HERE\n","    for word in word_l:\n","        \n","    ### END CODE HERE ###\n","    assert(x.shape == (1, 3))\n","    return x"],"metadata":{"id":"oUTAbCZk8b_x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Kiểm tra\n","# freqs tương tự mục 1.2\n","freqs = count_freq_words(train_x, train_y)\n","print(train_x[0])\n","extract_features(train_x[0], freqs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ox6yT-z_7bbt","executionInfo":{"status":"ok","timestamp":1665750476510,"user_tz":-420,"elapsed":1161,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"ae6dc280-ca28-4d34-a1b5-6086735a681d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[1.000e+00, 4.722e+03, 1.612e+03]])"]},"metadata":{},"execution_count":156}]},{"cell_type":"code","source":["# Kiểm tra\n","# freqs tương tự mục 1.2\n","# VD: các từ không có trong bộ `freq`\n","x_test = \"việt nam\"\n","extract_features(x_test, freqs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kVY_tIN58isS","executionInfo":{"status":"ok","timestamp":1665750479716,"user_tz":-420,"elapsed":399,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"}},"outputId":"98aef96b-6d37-4785-8aa8-275964b9e6e9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1., 0., 0.]])"]},"metadata":{},"execution_count":157}]},{"cell_type":"markdown","source":["###3.5.Huấn luyện mô hình Logistic Regression"],"metadata":{"id":"6oKSL2rc8xMZ"}},{"cell_type":"code","source":["# Tạo ma trận X có kích thước mxn với n=3 (số features)\n","X = np.zeros((len(train_x), 3))\n","for i in range(len(train_x)):\n","    X[i, :]= extract_features(train_x[i], freqs)\n","\n","Y = np.expand_dims(train_y, 1)\n","\n","# Huấn luyện với số vòng lặp 1500, tốc độ học 1e-6\n","J, theta = gradient_descent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n","print(f\"Cost {J.item()}.\")\n","print(f\"Weight {theta}\")"],"metadata":{"id":"sWoa3OEd8208"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###3.6.Dự đoán\n","* Tiền xử lý với dữ liệu thử nghiệm\n","* Tính `logits` dựa vào công thức\n","\n","$$y_{pred} = sigmoid(\\mathbf{x} \\cdot \\theta)$$"],"metadata":{"id":"UongNMjK9X5v"}},{"cell_type":"code","source":["# Ex 10\n","def predict_tweet(text, freqs, theta):\n","    '''\n","    Args: \n","        text: tweet\n","        freqs: bộ từ điển tần suất xuất hiện của từ theo label (word, label)\n","        theta: (3,1) vector trọng số\n","    Output: \n","        y_pred: xác suất dự đoán\n","    '''\n","    ### START CODE HERE\n","    \n","    # extract features\n","    # dự đoán\n","    \n","    ### END CODE HERE ###\n","    \n","    return y_pred"],"metadata":{"id":"BpS5jvnr-iXY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tests = [\"happy\", \"sad\"]\n","for t in tests:\n","    pred = predict_tweet(t, freqs, theta)\n","    print(f'{t} -> {pred}')"],"metadata":{"id":"ImETYplt-pc7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###3.7.Đánh giá độ chính xác trên tập test"],"metadata":{"id":"z4UjFnEt_BUW"}},{"cell_type":"code","source":["acc = 0\n","for sentence, label in zip(test_x, test_y):\n","\n","    # predic each sentence in test set\n","    pred = predict_tweet(sentence, freqs, theta)\n","\n","    if pred > 0.5:\n","        pred_l = 1\n","    else:\n","        pred_l = 0\n","\n","    # compare predict label with target label\n","    if int(pred_l) == int(label):\n","        acc += 1\n","\n","print('Accuracy: ', acc/len(test_x))"],"metadata":{"id":"xg2deATX_JXS"},"execution_count":null,"outputs":[]}]}