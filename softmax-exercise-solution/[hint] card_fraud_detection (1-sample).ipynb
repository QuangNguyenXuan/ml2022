{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM5/m8ljZ/sFsXgbKuCp8n7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 0. Tải bộ dữ liệu card_fraud_detection\n","(**Lưu ý:** nếu không tải được do bị giới hạn số lượt tải, các bạn hãy tải thủ công lên drive và copy vào colab)"],"metadata":{"id":"y8m6nlphiBzC"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZz-y60IxCk3","executionInfo":{"status":"ok","timestamp":1667217455081,"user_tz":-420,"elapsed":2721,"user":{"displayName":"Thắng Dương Đình","userId":"02196529682032971345"}},"outputId":"0e42bf65-6d51-43ee-b2b9-e38a87402af0"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1i35qEGnSrFxjYR777dWu2tyQ-zY-p-kx\n","To: /content/card_fraud_detection.zip\n","100% 69.2M/69.2M [00:00<00:00, 77.4MB/s]\n"]}],"source":["# https://drive.google.com/file/d/1i35qEGnSrFxjYR777dWu2tyQ-zY-p-kx/view?usp=sharing\n","!gdown --id 1i35qEGnSrFxjYR777dWu2tyQ-zY-p-kx"]},{"cell_type":"code","source":["!unzip 'card_fraud_detection.zip'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fVEUMTb3xV_y","executionInfo":{"status":"ok","timestamp":1667217456823,"user_tz":-420,"elapsed":1748,"user":{"displayName":"Thắng Dương Đình","userId":"02196529682032971345"}},"outputId":"0cee9d71-46a6-43c8-87a1-499d8925886d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  card_fraud_detection.zip\n","  inflating: creditcard.csv          \n"]}]},{"cell_type":"markdown","source":["# 1. Tiền xử lý dữ liệu"],"metadata":{"id":"3W4iguWIxMtm"}},{"cell_type":"markdown","source":["## 1.1. Đọc dữ liệu"],"metadata":{"id":"giWHr6gWxRCq"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm \n","\n","# Khai báo đường dẫn đến file dataset\n","dataset_path = \"./creditcard.csv\"\n","## Đọc dữ liệu file .csv sử dụng np.genfromtxt()\n","# Định nghĩa hàm lambda chuyển đổi giá trị string sang float \n","convert_label = lambda x: float(x.strip('\"') or -1)\n","# Đọc dataset\n","dataset = np.genfromtxt(dataset_path, # Đường dẫn dataset\n","                        delimiter=\",\", # Kí tự ngăn cách giữa các cột\n","                        skip_header=1, # Bỏ qua hàng đầu tiên (chứa tên của cột)\n","                        converters={-1: convert_label}, # Áp dụng hàm lambda vào cột cuối cùng (vì cột label đang có kiểu dữ liệu là string)\n","                        dtype=None, # dtype=None sẽ ép hàm genfromtxt phải tìm kiểu dữ liệu của từng cột một cách tuần tự\n","                        encoding=None) # Tắt tính năng mã hóa dữ liệu sang bytes"],"metadata":{"id":"onNFoe6jxRuK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_samples = dataset.shape[0] # Đọc số lượng mẫu dữ liệu trong dataset (bằng số hàng trong file csv)\n","n_classes = len(np.unique(dataset[:, -1])) # Đọc số lượng lớp đối tượng dự đoán trong dataset (bằng số lượng giá trị duy nhất của cột cuối cùng trong file .csv)\n","n_features = dataset.shape[1] - 1 # Đọc số lượng đặc trưng của bộ dữ liệu (bằng số cột trừ cột cuối cùng trong file .csv)\n","print('Số lượng mẫu dữ liệu (samples): ', n_samples)\n","print('Số lượng đặc trưng (features): ', n_features)\n","print('Số lượng lớp đối tượng (classes): ', n_classes)"],"metadata":{"id":"FZTEHKn3xjTJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.2. Trộn dữ liệu, tách independent/dependent variable, thêm bias, one hot encoding label, chuẩn hóa dữ liệu"],"metadata":{"id":"365aoAw0yvgR"}},{"cell_type":"code","source":["# Trộn (shuffle) dữ liệu\n","np.random.seed(1) # Cố định kết quả random \n","dataset = np.random.permutation(dataset)\n","# Tách independent varaible và depedent variable thành 2 biến X, y\n","X, y_idx = dataset[:, :-1].astype(np.float64), dataset[:, -1].astype(np.int32)\n","# One hot encoding label\n","y = np.array([np.zeros(n_classes) for _ in range(y_idx.shape[0])])\n","y[np.arange(len(y_idx)), y_idx] = 1\n","# Chuẩn hóa dữ liệu bằng phương pháp min-max normalization\n","X_min = np.min(X, axis=0)\n","X_max = np.max(X, axis=0)\n","X = (X - X_min) / (X_max - X_min)\n","# Tạo ma trận 1 (tượng trưng cho bias của mỗi sample)\n","bias = np.ones((X.shape[0], 1))\n","# Thêm bias vào X\n","X = np.hstack((bias, X))"],"metadata":{"id":"gwpKLLKCyxB8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.3. Chia tập Train/Val/Test"],"metadata":{"id":"Hwjx_zJdx0bb"}},{"cell_type":"code","source":["# Khai báo tỉ lệ kích thước của tập train/val/test (không nhất thiết khai báo cho test)\n","TRAIN_SIZE = 0.7\n","VAL_SIZE = 0.2\n","\n","# Tính chỉ mục kết thúc của train, test\n","TRAIN_IDX_END = int(TRAIN_SIZE * dataset.shape[0])\n","VAL_IDX_END = int(TRAIN_IDX_END + (VAL_SIZE * dataset.shape[0]))\n","\n","# Chia train/val/test sử dụng kĩ thuật indexing\n","X_train, y_train = X[:TRAIN_IDX_END], y[:TRAIN_IDX_END]\n","X_val, y_val = X[TRAIN_IDX_END:VAL_IDX_END], y[TRAIN_IDX_END:VAL_IDX_END]\n","X_test, y_test = X[VAL_IDX_END:], y[VAL_IDX_END:]"],"metadata":{"id":"Kx5vlZugxK2B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Xây dựng model"],"metadata":{"id":"7XLKcf8J2vdi"}},{"cell_type":"markdown","source":["## 2.1. Khai báo hàm tính softmax"],"metadata":{"id":"gaM5KTbQhWQ7"}},{"cell_type":"code","source":["# Xây dựng hàm dự đoán của model dùng softmax\n","def softmax(z):\n","  ### BẮT ĐẦU CODE TẠI ĐÂY ###\n","\n","  ### KẾT THÚC CODE TẠI ĐÂY ###\n","\n","  return p"],"metadata":{"id":"OboWR3YMhZuh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.2. Khai báo hàm dự đoán"],"metadata":{"id":"3A9yflHRhaVD"}},{"cell_type":"code","source":["# Xây dựng hàm dự đoán sử dụng softmax\n","def predict(X, theta):\n","  ### BẮT ĐẦU CODE TẠI ĐÂY ###\n","\n","  ### KẾT THÚC CODE TẠI ĐÂY ###\n","\n","  return y_hat"],"metadata":{"id":"FvwEYPkLhcZj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.3. Khai báo hàm tính loss (cross entropy)"],"metadata":{"id":"27TFWPSChdeD"}},{"cell_type":"code","source":["# Xây dựng hàm loss cross entropy\n","def loss(y, y_hat):\n","  ### BẮT ĐẦU CODE TẠI ĐÂY ###\n","\n","  ### KẾT THÚC CODE TẠI ĐÂY ###\n","\n","  return l"],"metadata":{"id":"mDwrFik4hhbv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.4. Khai báo hàm tính gradient"],"metadata":{"id":"vivEnxYuhp9y"}},{"cell_type":"code","source":["# Xây dựng hàm tính gradient\n","def gradient(X, y, y_hat):\n","  ### BẮT ĐẦU CODE TẠI ĐÂY ###\n","\n","  ### KẾT THÚC CODE TẠI ĐÂY ###\n","\n","  return grad"],"metadata":{"id":"Ry3Rw-hrhtDt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.5. Khai báo hàm đánh giá "],"metadata":{"id":"XkwsU-bmhh4n"}},{"cell_type":"code","source":["# Xây dựng hàm đánh giá\n","def evaluate(X_test, y_test, theta):\n","  accs = []\n","  losses = []\n","  n_samples = X_test.shape[0]\n","  n_features = X_test.shape[1]\n","  n_classes = np.unique(y_test, axis=0).shape[0]\n","\n","  ### BẮT ĐẦU CODE TẠI ĐÂY ###\n","\n","  ### KẾT THÚC CODE TẠI ĐÂY ###\n","  \n","  return sum(losses) / len(losses), sum(accs) / len(accs)"],"metadata":{"id":"cyjQYJ5GhoYA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.6. Khai báo hàm training"],"metadata":{"id":"AWwW62M3hvRa"}},{"cell_type":"code","source":["# Xây dựng hàm training\n","def fit(X_train, y_train, theta, EPOCHS=10, LR=1e-4, is_visualize=False):\n","  train_losses = []\n","  n_samples = X_train.shape[0]\n","  n_features = X_train.shape[1]\n","  n_classes = np.unique(y_train, axis=0).shape[0]\n","  for epoch in range(EPOCHS):\n","    progress_bar = tqdm(range(n_samples), desc=f\"EPOCH {epoch}\", position=0) # Tạo thanh progress thể hiện tiến độ training\n","    for i in progress_bar:\n","      # Đọc bộ mẫu dữ liệu tại batch i\n","      X_i = X_train[i]\n","      y_i = y_train[i]\n","\n","      X_i = X_i.reshape((n_features, 1))\n","      y_i = y_i.reshape((n_classes, 1))\n","\n","      # Dự đoán mẫu dữ liệu Xi\n","      y_hat = predict(X_i, theta)\n","\n","      # Tính train loss, train accuracy\n","      train_loss = loss(y_i, y_hat)[0][0]\n","      train_losses.append(train_loss)\n","\n","      # Tính gradient\n","      grad = gradient(X_i, y_i, y_hat)\n","\n","      # Cập nhật trọng số\n","      theta = theta - LR * grad\n","\n","      progress_bar.set_postfix({\"Train Loss\": train_loss}) # Thêm thông tin train loss vừa tính được vào thanh progress\n","\n","  print(\"\\nTRAINING COMPLETE\")\n","\n","  if is_visualize: # Plot đồ thị train loss nếu is_visualize = True\n","    plt.plot(train_losses, color='green')\n","    plt.title(\"Train loss over batch\")\n","    plt.show()\n","\n","  return theta"],"metadata":{"id":"XBxp4gYD20b8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Huấn luyện model"],"metadata":{"id":"HU2jpocI20xl"}},{"cell_type":"code","source":["# Khởi tạo bộ trọng số theta ngẫu nhiên (theo phân phối đồng nhất)\n","np.random.seed(1) # Cố định kết quả random \n","theta = np.random.uniform(size=(X_train.shape[1], np.unique(y_train, axis=0).shape[0]))"],"metadata":{"id":"s-PaR4nGIouN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Khai báo các siêu tham số (hyperparameters) và huấn luyện mô hình\n","EPOCHS = 1\n","LR = 1e-3\n","theta = fit(X_train, y_train, theta, EPOCHS, LR, is_visualize=True)"],"metadata":{"id":"CttDCex03Ioc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. Đánh giá model"],"metadata":{"id":"mQj6iPbI2377"}},{"cell_type":"code","source":["# Đánh giá trên tập validation\n","val_loss, val_acc = evaluate(X_val, y_val, theta)\n","print(\"Validation loss: \", np.round(val_loss, 3))\n","print(\"Validation accuracy: \", np.round(val_acc, 3))\n","\n","# Đánh giá trên tập test\n","test_loss, test_acc = evaluate(X_test, y_test, theta)\n","print(\"Test loss: \", np.round(test_loss, 3))\n","print(\"Test accuracy: \", np.round(test_acc, 3))"],"metadata":{"id":"CiWOwbfl3JFU"},"execution_count":null,"outputs":[]}]}