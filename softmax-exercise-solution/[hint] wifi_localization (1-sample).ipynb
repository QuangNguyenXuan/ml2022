{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMsLebQ3SX5cZcp3dmRx1nY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 0. Tải bộ dữ liệu wifi_localization\n","(**Lưu ý:** nếu không tải được do bị giới hạn số lượt tải, các bạn hãy tải thủ công lên drive và copy vào colab)"],"metadata":{"id":"y8m6nlphiBzC"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZz-y60IxCk3","executionInfo":{"status":"ok","timestamp":1667218158393,"user_tz":-420,"elapsed":1606,"user":{"displayName":"Thắng Dương Đình","userId":"02196529682032971345"}},"outputId":"ae3354dd-1c7a-4541-fa5d-fd8d1630e06f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1eCqW1U0djlHxREQETL4gsYC3pE-Ngihx\n","To: /content/wifi_localization.zip\n","100% 14.1k/14.1k [00:00<00:00, 15.3MB/s]\n"]}],"source":["# https://drive.google.com/file/d/1eCqW1U0djlHxREQETL4gsYC3pE-Ngihx/view?usp=share_link\n","!gdown --id 1eCqW1U0djlHxREQETL4gsYC3pE-Ngihx"]},{"cell_type":"code","source":["!unzip 'wifi_localization.zip'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fVEUMTb3xV_y","executionInfo":{"status":"ok","timestamp":1667218159511,"user_tz":-420,"elapsed":1119,"user":{"displayName":"Thắng Dương Đình","userId":"02196529682032971345"}},"outputId":"7c92b15a-ae50-462e-94a7-1113b394b40e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  wifi_localization.zip\n","  inflating: wifi_localization.csv   \n"]}]},{"cell_type":"markdown","source":["# 1. Tiền xử lý dữ liệu"],"metadata":{"id":"3W4iguWIxMtm"}},{"cell_type":"markdown","source":["## 1.1. Đọc dữ liệu"],"metadata":{"id":"giWHr6gWxRCq"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm \n","\n","# Khai báo đường dẫn đến file dataset\n","dataset_path = \"./wifi_localization.csv\"\n","## Đọc dữ liệu file .csv sử dụng np.genfromtxt()\n","# Đọc dataset\n","dataset = np.genfromtxt(dataset_path, # Đường dẫn dataset\n","                        delimiter=\",\", # Kí tự ngăn cách giữa các cột\n","                        skip_header=1, # Bỏ qua hàng đầu tiên (chứa tên của cột)\n","                        dtype=None, # dtype=None sẽ ép hàm genfromtxt phải tìm kiểu dữ liệu của từng cột một cách tuần tự\n","                        encoding=None) # Tắt tính năng mã hóa dữ liệu sang bytes"],"metadata":{"id":"onNFoe6jxRuK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_samples_glob = dataset.shape[0] # Đọc số lượng mẫu dữ liệu trong dataset (bằng số hàng trong file csv)\n","n_classes_glob = len(np.unique(dataset[:, -1])) # Đọc số lượng lớp đối tượng dự đoán trong dataset (bằng số lượng giá trị duy nhất của cột cuối cùng trong file .csv)\n","n_features_glob = dataset.shape[1] - 1 # Đọc số lượng đặc trưng của bộ dữ liệu (bằng số cột trừ cột cuối cùng trong file .csv)\n","print('Số lượng mẫu dữ liệu (samples): ', n_samples_glob)\n","print('Số lượng đặc trưng (features): ', n_features_glob)\n","print('Số lượng lớp đối tượng (classes): ', n_classes_glob)"],"metadata":{"id":"FZTEHKn3xjTJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.2. Trộn dữ liệu, tách independent/dependent variable, thêm bias, one hot encoding label, chuẩn hóa dữ liệu"],"metadata":{"id":"365aoAw0yvgR"}},{"cell_type":"code","source":["# Trộn (shuffle) dữ liệu\n","np.random.seed(1) # Cố định kết quả random \n","dataset = np.random.permutation(dataset)\n","# Tách independent varaible và depedent variable thành 2 biến X, y\n","X, y_idx = dataset[:, :-1].astype(np.float64), dataset[:, -1].astype(np.int32)\n","# One hot encoding label\n","y = np.array([np.zeros(n_classes_glob) for _ in range(y_idx.shape[0])])\n","y[np.arange(len(y_idx)), y_idx] = 1\n","# Chuẩn hóa dữ liệu bằng phương pháp min-max normalization\n","X_min = np.min(X, axis=0)\n","X_max = np.max(X, axis=0)\n","X = (X - X_min) / (X_max - X_min)\n","# Tạo ma trận 1 (tượng trưng cho bias của mỗi sample)\n","bias = np.ones((X.shape[0], 1))\n","# Thêm bias vào X\n","X = np.hstack((bias, X))"],"metadata":{"id":"gwpKLLKCyxB8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.3. Chia tập Train/Val/Test"],"metadata":{"id":"Hwjx_zJdx0bb"}},{"cell_type":"code","source":["# Khai báo tỉ lệ kích thước của tập train/val/test (không nhất thiết khai báo cho test)\n","TRAIN_SIZE = 0.7\n","VAL_SIZE = 0.2\n","\n","# Tính chỉ mục kết thúc của train, test\n","TRAIN_IDX_END = int(TRAIN_SIZE * dataset.shape[0])\n","VAL_IDX_END = int(TRAIN_IDX_END + (VAL_SIZE * dataset.shape[0]))\n","\n","# Chia train/val/test sử dụng kĩ thuật indexing\n","X_train, y_train = X[:TRAIN_IDX_END], y[:TRAIN_IDX_END]\n","X_val, y_val = X[TRAIN_IDX_END:VAL_IDX_END], y[TRAIN_IDX_END:VAL_IDX_END]\n","X_test, y_test = X[VAL_IDX_END:], y[VAL_IDX_END:]"],"metadata":{"id":"Kx5vlZugxK2B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Xây dựng model"],"metadata":{"id":"7XLKcf8J2vdi"}},{"cell_type":"markdown","source":["## 2.1. Khai báo hàm tính softmax"],"metadata":{"id":"gaM5KTbQhWQ7"}},{"cell_type":"code","source":["# Xây dựng hàm dự đoán của model dùng softmax\n","def softmax(Z):\n","  ### BẮT ĐẦU CODE TẠI ĐÂY ###\n","\n","  ### KẾT THÚC CODE TẠI ĐÂY ###\n","\n","  return p"],"metadata":{"id":"OboWR3YMhZuh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.2. Khai báo hàm dự đoán"],"metadata":{"id":"3A9yflHRhaVD"}},{"cell_type":"code","source":["# Xây dựng hàm dự đoán sử dụng softmax\n","def predict(X, theta):\n","  ### BẮT ĐẦU CODE TẠI ĐÂY ###\n","\n","  ### KẾT THÚC CODE TẠI ĐÂY ###\n","\n","  return y_hat"],"metadata":{"id":"FvwEYPkLhcZj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.3. Khai báo hàm tính loss (cross entropy)"],"metadata":{"id":"27TFWPSChdeD"}},{"cell_type":"code","source":["# Xây dựng hàm loss cross entropy\n","def loss(y, y_hat):\n","  ### BẮT ĐẦU CODE TẠI ĐÂY ###\n","\n","  ### KẾT THÚC CODE TẠI ĐÂY ###\n","\n","  return l"],"metadata":{"id":"mDwrFik4hhbv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.4. Khai báo hàm tính gradient"],"metadata":{"id":"vivEnxYuhp9y"}},{"cell_type":"code","source":["# Xây dựng hàm tính gradient\n","def gradient(X, y, y_hat):\n","  ### BẮT ĐẦU CODE TẠI ĐÂY ###\n","\n","  ### KẾT THÚC CODE TẠI ĐÂY ###\n","\n","  return grad"],"metadata":{"id":"Ry3Rw-hrhtDt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.5. Khai báo hàm đánh giá "],"metadata":{"id":"XkwsU-bmhh4n"}},{"cell_type":"code","source":["# Xây dựng hàm đánh giá\n","def evaluate(X_test, y_test, theta):\n","  accs = []\n","  losses = []\n","  n_samples = X_test.shape[0]\n","  n_features = X_test.shape[1]\n","  n_classes = np.unique(y_test, axis=0).shape[0]\n","\n","  ### BẮT ĐẦU CODE TẠI ĐÂY ###\n","\n","  ### KẾT THÚC CODE TẠI ĐÂY ###\n","  \n","  return sum(losses) / len(losses), sum(accs) / len(accs)"],"metadata":{"id":"cyjQYJ5GhoYA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.6. Khai báo hàm training"],"metadata":{"id":"AWwW62M3hvRa"}},{"cell_type":"code","source":["# Xây dựng hàm training\n","def fit(X_train, y_train, theta, EPOCHS=10, LR=1e-4, is_visualize=False):\n","  train_losses = []\n","  n_samples = X_train.shape[0]\n","  n_features = X_train.shape[1]\n","  n_classes = np.unique(y_train, axis=0).shape[0]\n","  for epoch in range(EPOCHS):\n","    progress_bar = tqdm(range(n_samples), desc=f\"EPOCH {epoch}\", position=0) # Tạo thanh progress thể hiện tiến độ training\n","    for i in progress_bar:\n","      # Đọc bộ mẫu dữ liệu tại batch i\n","      X_i = X_train[i]\n","      y_i = y_train[i]\n","\n","      X_i = X_i.reshape((n_features, 1))\n","      y_i = y_i.reshape((n_classes, 1))\n","\n","      # Dự đoán mẫu dữ liệu Xi\n","      y_hat = predict(X_i, theta)\n","\n","      # Tính train loss, train accuracy\n","      train_loss = loss(y_i, y_hat)[0][0]\n","      train_losses.append(train_loss)\n","\n","      # Tính gradient\n","      grad = gradient(X_i, y_i, y_hat)\n","\n","      # Cập nhật trọng số\n","      theta = theta - LR * grad\n","\n","      progress_bar.set_postfix({\"Train Loss\": train_loss}) # Thêm thông tin train loss vừa tính được vào thanh progress\n","\n","  print(\"\\nTRAINING COMPLETE\")\n","\n","  if is_visualize: # Plot đồ thị train loss nếu is_visualize = True\n","    plt.plot(train_losses, color='green')\n","    plt.title(\"Train loss over batch\")\n","    plt.show()\n","\n","  return theta"],"metadata":{"id":"XBxp4gYD20b8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Huấn luyện model"],"metadata":{"id":"HU2jpocI20xl"}},{"cell_type":"code","source":["# Khởi tạo bộ trọng số theta ngẫu nhiên (theo phân phối đồng nhất)\n","np.random.seed(1) # Cố định kết quả random \n","theta = np.random.uniform(size=(X_train.shape[1], np.unique(y_train, axis=0).shape[0]))"],"metadata":{"id":"s-PaR4nGIouN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Khai báo các siêu tham số (hyperparameters) và huấn luyện mô hình\n","EPOCHS = 100\n","LR = 1e-3\n","theta = fit(X_train, y_train, theta, EPOCHS, LR, is_visualize=True)"],"metadata":{"id":"CttDCex03Ioc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. Đánh giá model"],"metadata":{"id":"mQj6iPbI2377"}},{"cell_type":"code","source":["# Đánh giá trên tập validation\n","val_loss, val_acc = evaluate(X_val, y_val, theta)\n","print(\"Validation loss: \", np.round(val_loss, 3))\n","print(\"Validation accuracy: \", np.round(val_acc, 3))\n","\n","# Đánh giá trên tập test\n","test_loss, test_acc = evaluate(X_test, y_test, theta)\n","print(\"Test loss: \", np.round(test_loss, 3))\n","print(\"Test accuracy: \", np.round(test_acc, 3))"],"metadata":{"id":"CiWOwbfl3JFU"},"execution_count":null,"outputs":[]}]}